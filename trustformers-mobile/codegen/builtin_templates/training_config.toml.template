# {{name|title}} Training Configuration
# Generated by TrustformeRS Code Generation Framework

[model]
type = "{{model_type}}"
name = "{{name}}"
{{#each model_config}}
{{key}} = {{value}}
{{/each}}

[training]
# Basic training parameters
batch_size = {{batch_size|default:32}}
learning_rate = {{learning_rate|default:0.001}}
num_epochs = {{num_epochs|default:10}}
gradient_accumulation_steps = {{gradient_accumulation|default:1}}

# Optimization
optimizer = "{{optimizer|default:adam}}"
weight_decay = {{weight_decay|default:0.01}}
gradient_clipping = {{gradient_clip|default:1.0}}
{{#if optimizer == "adam"}}
adam_beta1 = 0.9
adam_beta2 = 0.999
adam_epsilon = 1e-8
{{/if}}

# Learning rate schedule
{{#if use_scheduler}}
scheduler = "{{scheduler_type|default:linear}}"
warmup_steps = {{warmup_steps|default:0}}
{{#if scheduler_type == "cosine"}}
cosine_cycles = 1
{{/if}}
{{/if}}

# Mixed precision
mixed_precision = {{mixed_precision|default:false}}
{{#if mixed_precision}}
loss_scale = "dynamic"
initial_loss_scale = 2048
{{/if}}

[data]
# Dataset configuration
train_data = "{{train_data_path}}"
{{#if val_data_path}}
val_data = "{{val_data_path}}"
{{/if}}
{{#if test_data_path}}
test_data = "{{test_data_path}}"
{{/if}}

# Data processing
{{#if is_sequence_model}}
max_sequence_length = {{max_length|default:512}}
tokenizer_path = "{{tokenizer_path}}"
{{/if}}
num_workers = {{num_workers|default:4}}
shuffle_train = true
drop_last = false

{{#if dataset_type == "image"}}
# Image preprocessing
image_size = [{{image_height|default:224}}, {{image_width|default:224}}]
normalize_mean = [0.485, 0.456, 0.406]
normalize_std = [0.229, 0.224, 0.225]
random_crop = true
random_flip = true
{{/if}}

[evaluation]
# Evaluation settings
eval_steps = {{eval_steps|default:500}}
eval_batch_size = {{eval_batch_size|default:64}}
save_best_model = true
metric_for_best_model = "{{best_model_metric|default:loss}}"
greater_is_better = {{greater_is_better|default:false}}

[checkpointing]
# Checkpoint settings
save_steps = {{save_steps|default:1000}}
save_total_limit = {{save_total_limit|default:3}}
checkpoint_dir = "./checkpoints/{{name}}"
resume_from_checkpoint = {{resume_from_checkpoint|default:false}}

[logging]
# Logging configuration
log_level = "{{log_level|default:info}}"
log_steps = {{log_steps|default:10}}
log_dir = "./logs/{{name}}"
use_tensorboard = {{use_tensorboard|default:false}}
use_wandb = {{use_wandb|default:false}}
{{#if use_wandb}}
wandb_project = "{{wandb_project}}"
wandb_entity = "{{wandb_entity}}"
{{/if}}

[distributed]
# Distributed training settings
distributed = {{distributed|default:false}}
{{#if distributed}}
backend = "{{distributed_backend|default:nccl}}"
local_rank = -1
world_size = -1
gradient_sync_steps = 1
{{/if}}

[performance]
# Performance optimizations
use_amp = {{use_amp|default:false}}
gradient_checkpointing = {{gradient_checkpointing|default:false}}
compile_model = {{compile_model|default:false}}
dataloader_pin_memory = {{pin_memory|default:true}}

{{#if custom_config}}
[custom]
# Custom configuration options
{{#each custom_config}}
{{key}} = {{value}}
{{/each}}
{{/if}}