# TrustformersRS Android Demo App

A comprehensive Android demo application built with Jetpack Compose showcasing the capabilities of TrustformersRS mobile inference framework.

## Features

### üß† Text Classification
- Real-time sentiment analysis
- BERT-based natural language understanding
- NNAPI hardware acceleration
- Performance metrics tracking

### üëÅÔ∏è Computer Vision
- Object detection using YOLO models
- Real-time image analysis
- GPU/Vulkan accelerated processing
- Bounding box visualization

### üìä Performance Monitoring
- Real-time system metrics
- CPU, GPU, and memory usage tracking
- Thermal state monitoring
- Battery impact analysis
- Inference queue monitoring

## Requirements

- Android 7.0+ (API level 24)
- 4GB+ RAM recommended
- GPU with Vulkan support (optional)
- 2GB+ available storage
- Camera permission for vision features

## Architecture

### Core Components

- **TrustformersEngine**: Main inference framework
- **NNAPI Integration**: Hardware acceleration using Android Neural Networks API
- **Vulkan Compute**: GPU-accelerated operations
- **Jetpack Compose UI**: Modern declarative UI framework

### Supported Backends

1. **NNAPI** (Android 8.1+)
   - Dedicated AI accelerator support
   - Vendor-specific optimizations
   - Automatic fallback handling

2. **Vulkan Compute** (Android 7.0+)
   - Cross-vendor GPU acceleration
   - Advanced compute shader support
   - Memory-efficient operations

3. **GPU** (OpenGL ES)
   - Legacy GPU acceleration
   - Broad device compatibility
   - Optimized for mobile GPUs

4. **CPU**
   - ARM NEON optimizations
   - Multi-threaded processing
   - Universal fallback

## Installation

### Option 1: APK Installation
1. Download the latest APK from releases
2. Enable "Install from unknown sources"
3. Install and grant required permissions

### Option 2: Build from Source
```bash
git clone https://github.com/trustformers/trustformers-mobile
cd trustformers-mobile/examples/android_demo_app
./gradlew assembleDebug
```

### Option 3: Android Studio
1. Open project in Android Studio
2. Sync Gradle dependencies
3. Run on device or emulator

## Dependencies

```kotlin
dependencies {
    implementation "com.trustformers:trustformers-android:1.0.0"
    implementation "androidx.compose.ui:compose-bom:2023.10.01"
    implementation "androidx.compose.ui:ui"
    implementation "androidx.compose.ui:ui-tooling-preview"
    implementation "androidx.compose.material3:material3"
    implementation "androidx.activity:activity-compose:1.8.0"
}
```

## Usage Examples

### Initialize Engine
```kotlin
val config = TrustformersConfig.Builder()
    .enableNNAPI(true)
    .enableGPU(true)
    .enableVulkan(true)
    .setMaxConcurrentInferences(2)
    .build()

val engine = TrustformersEngine.initialize(this, config)
```

### Load Models
```kotlin
// Load text classification model
engine.loadModel("bert-base", "models/bert_base.tflite")

// Load object detection model
engine.loadModel("yolo-v5", "models/yolo_v5.tflite")
```

### Text Classification
```kotlin
val result = engine.classifyText("This app is amazing!")
result.onSuccess { classification ->
    classification.predictions.forEach { prediction ->
        println("${prediction.label}: ${prediction.confidence}")
    }
}
```

### Object Detection
```kotlin
val result = engine.detectObjects(bitmap)
result.onSuccess { detection ->
    detection.detections.forEach { obj ->
        println("Found ${obj.className} at (${obj.bbox.x}, ${obj.bbox.y})")
    }
}
```

## Model Information

### Included Models
- **BERT-Base**: Text classification (500MB)
- **YOLOv5**: Object detection (300MB)
- **PoseNet**: Human pose estimation (200MB)

### Model Format Support
- TensorFlow Lite (.tflite)
- ONNX (.onnx) - via conversion
- Core ML (.mlmodel) - via conversion
- Custom formats with plugins

## Performance Benchmarks

### High-End Device (Snapdragon 8 Gen 2)
- Text Classification: ~12ms (NNAPI)
- Object Detection: ~18ms (GPU)
- Memory Usage: <300MB
- Power Consumption: <5% per hour

### Mid-Range Device (Snapdragon 7 Gen 1)
- Text Classification: ~20ms (NNAPI)
- Object Detection: ~35ms (GPU)
- Memory Usage: <400MB
- Power Consumption: <8% per hour

### Entry-Level Device (Snapdragon 6 Gen 1)
- Text Classification: ~45ms (CPU)
- Object Detection: ~80ms (CPU)
- Memory Usage: <500MB
- Power Consumption: <12% per hour

## Optimization Features

### Adaptive Performance
- Dynamic backend selection based on thermal state
- Quality scaling under performance constraints
- Automatic memory management

### Power Efficiency
- Battery-aware inference scheduling
- Thermal throttling protection
- Doze mode compatibility

### Memory Management
- Model unloading during memory pressure
- Garbage collection optimization
- Memory pool for efficient allocation

## Privacy & Security

- All inference runs on-device
- No data transmitted to external servers
- Model encryption at rest
- Secure model loading and validation

## Configuration Options

```kotlin
// Performance modes
config.setPowerMode(PowerMode.HIGH_PERFORMANCE)  // Maximum speed
config.setPowerMode(PowerMode.BALANCED)          // Balanced performance/power
config.setPowerMode(PowerMode.LOW_POWER)         // Maximum battery life

// Backend preferences
config.enableNNAPI(true)    // Use dedicated AI hardware
config.enableVulkan(true)   // Use Vulkan compute shaders
config.enableGPU(true)      // Use OpenGL ES compute
config.useQuantization(true) // Enable INT8 quantization
```

## Troubleshooting

### Common Issues

**App crashes on startup**
- Check available memory (>1GB free recommended)
- Ensure Android version compatibility
- Verify app permissions

**Poor inference performance**
- Enable hardware acceleration in settings
- Close background apps to free memory
- Check thermal throttling status

**Models fail to load**
- Verify sufficient storage space
- Check file permissions
- Ensure model format compatibility

### Debug Information

Enable debug logging:
```kotlin
TrustformersEngine.setLogLevel(LogLevel.DEBUG)
```

Performance profiling:
```kotlin
val stats = engine.getRuntimeStats()
println("Average inference: ${stats.averageInferenceTimeMs}ms")
println("Success rate: ${stats.successRate * 100}%")
```

Device capabilities:
```kotlin
val deviceInfo = engine.getDeviceInfo()
println("NNAPI support: ${deviceInfo.hasNNAPI}")
println("Vulkan support: ${deviceInfo.hasVulkan}")
```

## Advanced Features

### Custom Models
```kotlin
// Load custom TensorFlow Lite model
engine.loadCustomModel("my-model", "path/to/model.tflite") { builder ->
    builder.setInputShape(0, intArrayOf(1, 224, 224, 3))
    builder.setOutputShape(0, intArrayOf(1, 1000))
}
```

### Batch Processing
```kotlin
val images = listOf(bitmap1, bitmap2, bitmap3)
val results = engine.detectObjectsBatch(images)
```

### Real-time Processing
```kotlin
// Camera preview integration
cameraPreview.addFrameProcessor { frame ->
    engine.detectObjects(frame.bitmap) { result ->
        updateUI(result)
    }
}
```

## Testing

### Unit Tests
```bash
./gradlew testDebugUnitTest
```

### Instrumentation Tests
```bash
./gradlew connectedAndroidTest
```

### Performance Tests
```bash
./gradlew benchmarkDebug
```

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/new-feature`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/new-feature`)
5. Create Pull Request

## License

This demo app is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- üìß Email: android-support@trustformers.ai
- üí¨ Discord: [TrustformersRS Android Community](https://discord.gg/trustformers-android)
- üìñ Documentation: [android-docs.trustformers.ai](https://android-docs.trustformers.ai)
- üêõ Issues: [GitHub Issues](https://github.com/trustformers/trustformers-mobile/issues)
- üì± Telegram: [TrustformersRS Mobile](https://t.me/trustformers_mobile)